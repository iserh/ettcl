{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing PLAID Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import torch\n",
    "import random\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from ettcl.modeling import ColBERTModel, ColBERTTokenizer\n",
    "from ettcl.encoding import ColBERTEncoder\n",
    "from ettcl.searching.colbert_searcher import ColBERTSearcher, _SearcherSettings\n",
    "from ettcl.logging import configure_logger\n",
    "import colbert.search.index_storage as index_storage\n",
    "\n",
    "configure_logger(\"INFO\")\n",
    "\n",
    "model_path = \"../training/imdb/bert-base-uncased/2023-06-30T09:30:28.027860/checkpoint-7500\"\n",
    "index_path = \"../training/imdb/bert-base-uncased/2023-06-30T09:30:28.027860/checkpoint-7500/index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ColBERTModel.from_pretrained(model_path)\n",
    "tokenizer = ColBERTTokenizer.from_pretrained(model_path)\n",
    "encoder = ColBERTEncoder(model, tokenizer)\n",
    "searcher = ColBERTSearcher(index_path, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2_000\n",
    "\n",
    "encoder.cuda()\n",
    "Q = encoder.encode_queries(dataset.select(range(n))[\"text\"], to_cpu=False)\n",
    "encoder.cpu()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Memory:\", torch.cuda.memory_allocated() / 1e9)\n",
    "\n",
    "Q[0].shape, Q[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = '''\n",
    "import random\n",
    "random.seed(12345)\n",
    "'''\n",
    "\n",
    "def search(searcher, args, Q, k):\n",
    "    idx = random.randint(0, 2000)\n",
    "    searcher.dense_search(Q[idx], k=128, args=args)\n",
    "\n",
    "def profile(searcher, args, Q, k):\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    idle_memory = torch.cuda.memory_allocated()\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"performance-analysis\",\n",
    "        config={\"k\": k, **args.__dict__, \"idle_memory\": idle_memory},\n",
    "        save_code=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    r, n = 5, 200\n",
    "    timer = timeit.Timer(\n",
    "        \"search(searcher, args, Q, k)\",\n",
    "        setup=setup,\n",
    "        globals={\"search\": search, \"searcher\": searcher, \"args\": args, \"Q\": Q, \"k\": k}\n",
    "    )\n",
    "\n",
    "    time = min(timer.repeat(r, n)) / n\n",
    "    print(time)\n",
    "\n",
    "    print(f\"{time * 1000:.3f} ms\")\n",
    "    memory = torch.cuda.max_memory_allocated()\n",
    "    print(f\"Memory: {memory / 1e9:.3f} GB ({idle_memory / 1e9:.3f} GB idle)\")\n",
    "\n",
    "    run.log({\n",
    "        \"execution_time\": time,\n",
    "        \"max_memory\": memory,\n",
    "    })\n",
    "    run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching on GPU, approx. index operations on CPU/GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = [q.cuda() for q in Q]\n",
    "searcher.ranker = index_storage.IndexScorer(index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    centroid_score_threshold=0.8,\n",
    "    plaid_num_elem_batch=3e8,\n",
    "    skip_plaid_stage_3=False,\n",
    "    plaid_stage_2_3_cpu=False,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    centroid_score_threshold=0.8,\n",
    "    plaid_num_elem_batch=3e8,\n",
    "    skip_plaid_stage_3=True,\n",
    "    plaid_stage_2_3_cpu=False,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    plaid_num_elem_batch=3e8,\n",
    "    skip_plaid_stage_3=False,\n",
    "    plaid_stage_2_3_cpu=False,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    plaid_num_elem_batch=3e8,\n",
    "    skip_plaid_stage_3=True,\n",
    "    plaid_stage_2_3_cpu=False,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    centroid_score_threshold=0.8,\n",
    "    plaid_num_elem_batch=3e9,\n",
    "    skip_plaid_stage_3=False,\n",
    "    plaid_stage_2_3_cpu=False,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    centroid_score_threshold=0.8,\n",
    "    plaid_num_elem_batch=3e9,\n",
    "    skip_plaid_stage_3=True,\n",
    "    plaid_stage_2_3_cpu=False,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    plaid_num_elem_batch=3e9,\n",
    "    skip_plaid_stage_3=False,\n",
    "    plaid_stage_2_3_cpu=False,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    plaid_num_elem_batch=3e9,\n",
    "    skip_plaid_stage_3=True,\n",
    "    plaid_stage_2_3_cpu=False,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    centroid_score_threshold=0.8,\n",
    "    plaid_stage_2_3_cpu=True,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    ncells=1,\n",
    "    plaid_stage_2_3_cpu=True,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching entirely on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = [q.cpu() for q in Q]\n",
    "searcher.ranker = index_storage.IndexScorer(index_path, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _SearcherSettings(\n",
    "    gpus=0,\n",
    "    ncells=1,\n",
    "    centroid_score_threshold=0.8,\n",
    ")\n",
    "\n",
    "profile(searcher, args, Q, k=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: Searching whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from ettcl.modeling import ColBERTModel, ColBERTTokenizer\n",
    "from ettcl.encoding import ColBERTEncoder\n",
    "from ettcl.searching.colbert_searcher import ColBERTSearcher, ColBERTSearcherConfig\n",
    "from ettcl.utils.multiprocessing import run_multiprocessed\n",
    "from ettcl.utils import catchtime\n",
    "\n",
    "model_path = \"../training/imdb/bert-base-uncased/2023-06-30T09:30:28.027860/checkpoint-7500\"\n",
    "index_path = \"../training/imdb/bert-base-uncased/2023-06-30T09:30:28.027860/checkpoint-7500/index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ColBERTModel.from_pretrained(model_path)\n",
    "tokenizer = ColBERTTokenizer.from_pretrained(model_path)\n",
    "encoder = ColBERTEncoder(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(dataset, config, num_proc, k):\n",
    "    searcher = ColBERTSearcher(index_path, encoder, config)\n",
    "    dataset = dataset.map(\n",
    "        run_multiprocessed(searcher.search),\n",
    "        input_columns=\"text\",\n",
    "        fn_kwargs={\"k\": k},\n",
    "        batched=True,\n",
    "        batch_size=1_000,\n",
    "        with_rank=True,\n",
    "        num_proc=num_proc,\n",
    "    )\n",
    "\n",
    "def profile(dataset, config, num_proc, k):\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    idle_memory = torch.cuda.memory_allocated()\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"performance-analysis\",\n",
    "        config={\"k\": k, \"num_proc\": num_proc, \"idle_memory\": idle_memory, **config.__dict__},\n",
    "        save_code=True,\n",
    "    )\n",
    "\n",
    "    with catchtime() as time:\n",
    "        search(dataset, config, num_proc, k)\n",
    "\n",
    "    run.log({\"execution_time\": time})\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ColBERTSearcherConfig(plaid_stage_2_3_cpu=True)\n",
    "profile(dataset, config, num_proc=4, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ColBERTSearcherConfig(plaid_stage_2_3_cpu=True)\n",
    "profile(dataset, config, num_proc=2, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ColBERTSearcherConfig(plaid_stage_2_3_cpu=False)\n",
    "profile(dataset, config, num_proc=4, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ColBERTSearcherConfig(plaid_stage_2_3_cpu=False)\n",
    "profile(dataset, config, num_proc=2, k=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
